\chapter{Conclusioni e sviluppi futuri}
Da quando 10-15 anni fa gli Online Social Network hanno iniziato a far parte delle vite di ciascun individuo, molti più dati vengono condivisi in rete. Tantissime persone divulgano spesso inconsapevolmente dati personali e sensibili che minano la privacy propria e degli altri. Nasce quindi l'esigenza di proteggere le persone non solo, come già avviene~\cite{}, da tracker in rete, ma anche da loro stessi, muovendosi verso un concetto di privacy un po' diverso, esteso, che può essere riassunto come segue: \textit{ \quotes{privacy as having the ability to control the dissemination of sensitive information}}.

Per questo motivo sorge la necessità di avere strumenti adatti a fornire consapevolezza agli utenti, avvertirli prima della divulgazione di informazioni sensibili o personali, fornendo quindi un meccanismo di difesa basato sul \textit{nudge}. Knoxly, è un tool per Google Chrome che, utilizzando meccanismi lessicali per individuare dati sensibili e personali in messaggi di testo scritti in linguaggio naturale, fornisce agli utenti consapevolezza rispetto alla privacy. Tale tool nella sua prima versione mostra delle limitazioni dovute proprio alla rigidità dei meccanismi basati sui lessemi. 

In questo lavoro sono state ampliate le funzionalità di Knoxly. Il tool ora ha a disposizione quattro moduli \quotes{intelligenti} principali: (a) \textit{embedding module}, (b) \textit{topic classifier}, (c) \textit{sensitiveness classifier} e (d) \textit{customized sensitiveness classifier}. L'\textit{embedding module} è basato su tecniche di sentence embedding, il suo compito è di trasformare il testo in linguaggio naturale in un vettore n-dimensionale di lunghezza fissa. Il \textit{topic classifier} è basato sul modello Random Forest, il suo compito è comprendere l'argomento di cui parla il testo ed è in grado di farlo su cinque topic: health, politics, job, travel, general. Il \textit{sensitiveness classifier} è basato sul modello Random Forest, il suo compito è di rilevare il livello di sensibilità dei contenuti del testo in base all'argomento. Infine, il \textit{customized sensitiveness classifier} è basato sul modello Passive-Aggressive (in particolare PAII), il suo compito è comprendere la propensione dell'utente alla divulgazione di determinati contenuti online ed imparare dai suoi feedback in modo da non segnalare contenuti che per l'utente sono innocui. 

Knoxly nella sua nuova versione è stato oggetto di una intensa fase di benchmarking volta a misurarne l'efficacia e l'efficienza. Per l'efficacia abbiamo notato come il tool sia particolarmente più performante quando analizza testi lunghi ($l>70$). Ciò è dovuto soprattutto ai dataset utilizzati per addestrare i vari moduli e alla difficoltà di comprendere la semantica e la sensibilità di un testo molto breve ($l \leq 70$). Per quanto concerne l'efficienza, Knoxly mostra risultati promettenti, con un utilizzo molto esiguo delle risorse della macchina su cui è installato, ed il backend elabora molto velocemente le richieste (meno di 1.6 secondi nel 90\% dei casi).

È possibile inoltre utilizzare il backend di questo plug-in come un framework utile per individuare dati sensibili e personali. Infatti basterà cambiare i dataset di partenza e seguire la metodologia descritta nel Capitolo~\ref{ch:method} per addestrare nuovamente i classificatori a riconoscere nuovi o più tipi di dati sensibili. A tal proposito, infatti, si può affermare che i dataset di partenza vanno ampliati, resi più eterogenei, aggiungendo nuove opinioni politiche, nuove patologie, nuove frasi che trattano di lavoro e viaggi. Così facendo il Topic classifier avrà una conoscenza maggiore e il numero di falsi positivi da lui individuato diminuirà riuscendo così ad ottenere predizioni sempre più precise.

Se si ampliano i dataset utilizzati dal Topic classifier allora non si può non pensare ad ampliare la taglia del dataset utilizzato per costruire i vari Sensitiveness classifier; questa scelta però non è molto semplice dato che le entry che fanno parte del dataset che va dato in input ai veri Sensitiveness classifier vanno sempre etichettate manualmente da un esperto del dominio: una operazione delicata che richiede molto tempo.

Oltre ad ampliare i dataset per addestrare i vari moduli, si può anche pensare di aumentare la taglia dei topic da analizzare. Durante questo lavoro di tesi un evento tragico ha shockato il mondo, dando modo a chiunque di porsi qualche domanda in più riguardo il razzismo. L'evento in questione è la morte di George Floyd\footnote{\url{https://en.wikipedia.org/wiki/Killing_of_George_Floyd}}. Si potrebbe pensare di aggiungere una nuovo topic all'interno di Knoxly ovvero \textit{racism}. Supportato da un buon dataset di addestramento Knoxly sarebbe in grado di individuare contenuti sensibili riguardanti l'origine razziale di una persona e la sua opinione in merito (che spesso si mescola con affinità politiche). Un altro topic che si può pensare di aggiungere è \textit{sexual}, ovvero, addestrare Knoxly a riconoscere frasi che trattano l'orientamento e/o le preferenze sessuali di una persona. Purtroppo dataset di questo genere non esistono ancora, perciò l'unico modo per proseguire in questa direzione è sviluppare una strategia di raccolta dati.

Analizzando manualmente i testi per effettuare l'analisi quantitativa (Sez. \ref{sec:qualitative}) si è evinto che l'euristica di input definita in Sez.~\ref{ssec:euristicInput} non risulta essere molto efficace dato che invia le frasi al server anche quando non è necessario: ad esempio, se viene scritto un testo più lungo di 5 caratteri ma esso contiene una abbreviazione come \quotes{Dott.} allora questo viene inviato al server che analizzerà una frase che non è realmente terminata.