Per realizzare l'intelligenza artificiale di Knoxly è stata seguita una metodologia che si suddivide nelle seguenti fasi:
\begin{itemize}
    \item Data collection: raccolta data e pre-processing dei dati
    \item Topic classification: realizzare una modello che data una frase è in grado di riconoscere il topic di appartenenza
    \item Sensitivity classification: realizzare un modello che data una frase è in grado di capire quanto essa sia sensibile
\end{itemize}
\section{Data collection}
Per creare il dataset che verrà utilizzato per addestrare l'IA bisogna come prima cosa raccogliere i dati raw (non elaborati). Questi sono stati presi da vari dataset messi a disposizione dal sito \href{https://www.kaggle.com/}{kaggle.com} dopodichè sono stati \quotes{puliti} e uniti in un unico dataset. Di seguito vengono elencati i dataset selezionati:\newline
\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Topic} & \textbf{nome dataset} & \textbf{num. elementi} \\ \hline
Politics & Election Day Tweets & 393.764 \\ \hline
Health & Medical Transcriptions & 2.348 \\ \hline
Health & Medical Speech, Transcription, and Intent & 706 \\ \hline
Job & AMAZON Job Skills & 2.505 \\ \hline
Travel & Twitter US Airline Sentiment & 14.427 \\ \hline
General & The Movies Dataset & 44.306 \\ \hline
\end{tabular}
\caption{dateset utilizzati e numero di entry}
\end{table}
\FloatBarrier
Si è deciso di introdurre un topic che chiameremo \quotes{General} questo topic ci servirà per aumentare l'eterogeneità dei dati. In questo topic sono contenute delle trame di film, sono state scelte le trame perchè queste sono composte da testi brevi e raccontano una storia e in alcuni casi questa può riportare dei dati sensibili riguardo i personaggi.\newline
I dataset scelti sono composti da file .csv essi presentano diverse colonne alcune di queste irrilevanti per questo lavoro.\newline
Di seguito verranno elencati i file scelti e le colonne selezionate che comporranno il dataset
\begin{table}[h]
\centering
\begin{tabular}{|l|c|l|}
\hline
\multicolumn{1}{|c|}{\textbf{Topic}} & \textbf{file} & \multicolumn{1}{c|}{\textbf{col. scelta}} \\ \hline
Politics & election\_day\_tweets.csv & colonna: text \\ \hline
Health & mtsamples.csv & description \\ \hline
Health & overview-of-recordings.csv & phrase \\ \hline
Job & amazon\_jobs\_dataset.csv & \begin{tabular}[c]{@{}l@{}}description,\\ basic qualifications,\\ preferred qualifications\end{tabular} \\ \hline
Travel & Tweets.csv & text \\ \hline
General & movie\_metadata.csv & overview \\ \hline
\end{tabular}
\caption{file e colonne selezionate dai dataset di kaggle}
\end{table}
\FloatBarrier

\section{Preprocessing sui raw data}
\label{sec:preprocessingraw}
I testi selezionati risultano molto eterogenei quindi prima di raggruppare tutto in un unico dataset è stata necessaria una pulizia di questi dati.\newline
Dai vari subset ricavati dai dataset originali di kaggle sono state eliminate le righe che contenevano un testo di lunghezza inferiore ai 3 caratteri e che non erano in lingua inglese. La fase language detection è stata fata utilizzando la libreria Python  TextBlob\footnote{\url{https://textblob.readthedocs.io/en/dev}}.\newline
Si è notato che in dati appartenenti alla categoria lavoro risultano essere molto grandi, questo è un problema perchè potrebbe generare un numero molto alto di falsi positivi durante la fase di sesitiveness labeling. Per ridurre le dimensioni delle singole entry appartenti alla categoria job si è deciso di dividere in varie parti l'annuncio di lavoro, questa operazione è stata fatta utilizzando il sentence splitter\footnote{\url{https://github.com/berkmancenter/mediacloud-sentence-splitter}}.\newline
Come ultima cosa dal testo contenuto in ogni riga è stata rimossa la punteggiatura, terminata questa fase i vari dataset processati sono pronti per essere uniti ed etichettati.

\section{Topic classification}

\subsection{Creazione del dataset}
Una volta ultimata la fase di pre-processing i dati sono stati uniti in unico dataset
\subsubsection{Topic Labeling}
\label{sssec:topiclabeling}
La fase di labeling è l'ultimo step prima di ottenere il dataset il dataset che verrà utilizzato per la topic classification. A seconda del topic trattato dal dataset \quotes{ripulito} accanto alla colonna contenente i testi viene aggiunta una nuovo colonna esse contiene un numero che identifica univocamente il topic a cui la frase fa riferimeto.
\FloatBarrier
\begin{table}[h]
\centering
\begin{tabular}{|c|c|}
\hline
\textbf{Topic} & \textbf{ID} \\ \hline
Politics & 0 \\ \hline
Health & 1 \\ \hline
Job & 2 \\ \hline
Travel & 3 \\ \hline
General & 4 \\ \hline
\end{tabular}
\end{table}
Una volta completato il labelling tutti i singoli dataset vengo uniti in un unico dataset da 2 colonne(testo, topic) da più mezzo milione di righe, da queste verranno selezionati tre campioni uno da 200(\textit{ds200.csv)}, uno da 1000(\textit{ds1000.csv}) e un altro da 2000 entry per ogni topic(\textit{ds2000.csv}).\newline
I dataset da 1000 e da 2000 andranno in input ad un primo classificatore mentre il dataset da 200 entry per topic sarà sottoposto ad una seconda fase di labeling.

\subsubsection{Rappresentazione del testo}
\label{sssec:rappresentazione}
Per rappresentare i testi nel nostro dataset abbiamo utilizzato Universal Sentence Encoder, esso ci permette di rappresentare una frase scritta in linguaggio naturale in un vettore da 512 elementi.\newline
Abbiamo effettuato l'embed di tutti gli elementi presenti in \textit{ds1000.csv}, quindi ogni riga appartenente ad ogni topic sarà composta da un vettore da 512 elementi
\FloatBarrier
\begin{table}[h]
\centering
\begin{tabular}{|c|c|}
\hline
\textbf{Embed} & \textbf{Topic} \\ \hline
Politics{[}512{]} & 0 \\ \hline
Health{[}512{]} & 1 \\ \hline
Job{[}512{]} & 2 \\ \hline
Travel{[}512{]} & 3 \\ \hline
General{[}512{]} & 4 \\ \hline
\end{tabular}
\end{table}
Le frasi di cui è stato fatto l'embed vengono salvate in \textit{X\_embed}, mentre le label di rifiremto per ogni frase sono stata salvate i \textit{y}. Possiamo dire che \textit{X\_embed} e \textit{y} sono una nuova rappresentazione di \textit{ds1000.csv}

\subsection{Validation}
Inizialmente abbiamo diviso in due subset \textit{ds1000.csv} il primo, il \textbf{training set}, ottenuto l'80\% degli elementi scelti in maniera casuale, il secondo, il \textbf{test set} ottenuto includendo il restante 20\% degli elementi.\newline
Come detto in precedenza il dataset risulta bilanciato dato che abbiamo usato solo 1000 elementi per ogni topic, quindi per validare il modello è stata usata la 5-fold cross-validation usando il metodo \textit{GridSearchCV}.\newline
La \textbf{k-fold} cross-validation è una procedura di resampling utilizzata per valutare modelli di machine learning su un campione di dati limitato. La procedura ha come unico parametro \textit{k} che rappresenta il numero di quanti subset si devono creare partendo dal campione originale, nel nostro caso $ k = 5 $.\newline
Il modello utilizzato per addestrare il classificatore è il \textbf{Random Forest} esso prende in input gli embed e il numero dei vari estimatori che hanno il compito di .... La seguente tabella mostra il numero di estimatori utilizzati e i risultati ottenuti

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{# estimatori} & \textbf{Variazione} & \textbf{Risultato} \\ \hline
17 & +/-0.012 & 0.948 \\ \hline
37 & +/-0.010 & 0.963 \\ \hline
51 & +/-0.009 & 0.965 \\ \hline
177 & +/-0.006 & 0.966 \\ \hline
213 & +/-0.006 & 0.968 \\ \hline
517 & +/-0.005 & 0.966 \\ \hline
\end{tabular}
\end{table}
\FloatBarrier

\subsection{Testing}

La tabella seguente riporta le performance ottenute da questo classificatore al termine della prima fase
\begin{table}[h]
\begin{tabular}{|l|l|c|c|c|c|c|}
\hline
\multirow{2}{*}{\textbf{Classifier}} & \multirow{2}{*}{\textbf{Metric}} & \multicolumn{5}{c|}{\textbf{Topics}} \\ \cline{3-7} 
 &  & Politics & Health & Job & Travel & General \\ \hline
\multirow{4}{*}{RF} & Accuracy & \multicolumn{5}{c|}{0.983} \\ \cline{2-7} 
 & Precision & 0.979 & 0.99 & 0.985 & 0.966 & 0.994 \\ \cline{2-7} 
 & Recall & 0.965 & 0.995 & 0.985  & 0.995 & 0.975 \\ \cline{2-7} 
 & Fscore & 0.972 & 0.992 & 0.985 & 0.980 & 0.984 \\ \hline
\end{tabular}
\caption{misure training ds1000.csv}
\end{table}
\FloatBarrier
commento delle misure.\newline
Nella seconda fase viene effettuato il \quotes{testing into the wild} dove la predizione del topic di appartenza dell'embed di una frase viene fatta su un dataset molto più grande nel nostro caso \textit{ds2000.csv}.\newline
La tabella seguente riporta le misure ottenute dalla seconda fase. 
\begin{table}[h]
\begin{tabular}{|l|l|c|c|c|c|c|}
\hline
\multirow{2}{*}{\textbf{Classifier}} & \multirow{2}{*}{\textbf{Metric}} & \multicolumn{5}{c|}{\textbf{Topics}} \\ \cline{3-7} 
 &  & Politics & Health & Job & Travel & General \\ \hline
\multirow{4}{*}{RF} & Accuracy & \multicolumn{5}{c|}{0.988} \\ \cline{2-7} 
 & Precision & 0.992 & 0.995 & 0.985 & 0.975 & 0.993 \\ \cline{2-7} 
 & Recall & 0.969 & 0.995 & 0.993 & 0.996 & 0.988 \\ \cline{2-7} 
 & Fscore & 0.980 & 0.995 & 0.989 & 0.985 & 0.999 \\ \hline
\end{tabular}
\caption{misure validation ds2000.csv}
\end{table}
\FloatBarrier
commento delle misure.\newline

\section{Senstivity classification}

\subsection{Creazione Dataset sensitivity}

\subsubsection{Sensitive labeling}
In questa fase a ds200.csv è stata aggiunta una terza colonna denominata \quotes{sensibile}, nella quale verrà scritto \textbf{1} se la riga contiene un dato sensibile 0 altrimenti.\newline
Prima di etichettare le entry sensibili, determinare al meglio quando un dato è sensibile o meno ci siamo rifatti allo studio di Rumbald et al.\cite{dataSpectrum}

\paragraph{Tabella delle sensibilità}
In accordo allo studio fatto da Rumbal sono state identficate le seguenti regole
\FloatBarrier
\begin{table}[h]
\begin{tabular}{|l|c|}
\hline
\multicolumn{1}{|c|}{\textbf{Regole}} & \textbf{Sensibile} \\ \hline
Dati relativi ad oggetti & No \\ \hline
Dati anonimizzati relativi a persone & No \\ \hline
Dati relativi ad interazioni uomo-macchina & No \\ \hline
Dati relativi a posizione di uomini & \textbf{Sì} \\ \hline
Dati relativi ad abitudini di acquisto & No \\ \hline
Dati relativi allo stipendio & \textbf{Sì} \\ \hline
Dati relativi al lavoro svolto & \textbf{Sì} \\ \hline
Dati relativi alla propria classe sociale & \textbf{Sì} \\ \hline
Indirizzo o luogo & \textbf{Sì} \\ \hline
Chiara opinione religiosa o politica & \textbf{Sì} \\ \hline
Altri tipi di opinioni & No \\ \hline
Dati sul lifestyle & \textbf{Sì} \\ \hline
Orientamento sessuale & \textbf{Sì} \\ \hline
Sesso in generale & No \\ \hline
Dati relativi alla gravidanza & \textbf{Sì} \\ \hline
Dati relativi al gruppo etnico & \textbf{Sì} \\ \hline
Dati medici o stato di salute & \textbf{Sì} \\ \hline
\end{tabular}
\end{table}
\FloatBarrier
descrizione dettagliata delle regole?\newline
\subsection{Fase di labeling}
Una volta dettate le regole per il labeling si è proceduto ad etichettare manualmente ogni singola entry come sensibile(1) o non sensibile(0).\newline
%Dopo una prima etichettatura abbiamo ottenuto il seguente numero di topic sensibili per categoria\newline
\begin{table}[t]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Topic} & \textbf{\# entry} & \textbf{\# entry sensibili} \\ \hline
Politics & 200 & 40 \\ \hline
Health & 200 & 100 \\ \hline
Job & 200 & 21 \\ \hline
Travel & 200 & 28 \\ \hline
General & 200 & 71 \\ \hline
Totale & 1000 & 260 \\ \hline
\end{tabular}
\caption{numero entry sensibili per categoria}
\end{table}
\FloatBarrier
Si è osservato che il dataset risulta molto sbilanciato, in particolare nel topic health i tipi di interventi che ricorrono spesso sono quelli alla prostata e all'ernia, mentre nel topic job si fa riferimento a figure lavorative solo nel campo IT. Il topic più sorprendente è stato il topic General dato che i dati sensibili appartenenti ad esso fanno parte delle categorie più disparate.\newline
Per bilanciare il dataset sono state rimosse entry sensibili dai topic che ne avevano in abbondanza ed aggiungete nuove entry sensibili nei topic dove ne erano presenti di meno. Le nuove entry da aggiungere sono state selezionate manualmente da ds1000.csv, mentre le entry da rimuovere sono state quelle che trattavano argomenti ripetuti molte volte all'interno del topic.\newline
\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Topic} & \textbf{\# entry} & \textbf{\# entry sensibili} \\ \hline
Politics & 200 & 40 \\ \hline
Health & 200 & 102 \\ \hline
Job & 200 & 21 \\ \hline
Travel & 200 & 28 \\ \hline
General & 200 & 71 \\ \hline
Totale & 1000 & 262 \\ \hline
\end{tabular}
\caption{numero entry sensibili dopo il bilanciamento}
\end{table}