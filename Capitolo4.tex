Per blabla è stata progettata una metodologia che si suddivide nelle seguenti fasi:
\begin{itemize}
    \item Data collection:
    \item Text classification:
        \begin{itemize}
            \item 
        \end{itemize}
    \item Sensitivity classification:
        \begin{itemize}
            \item 
        \end{itemize}
\end{itemize}
\section{Raw Data}
Per creare il dataset che verrà utilizzato per addestrare l'IA bisogna come prima cosa raccogliere i dati raw (non elaborati). Questi sono stati presi da vari dataset messi a disposizione dal sito \href{https://www.kaggle.com/}{kaggle.com} dopodichè sono stati \quotes{puliti} e uniti in un unico dataset.
Per ogni topic scelto sono stati presi dei dataset da kaggle, i dataset sceltisono i seguenti:
\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Topic} & \textbf{link} & \textbf{num. elementi} \\ \hline
Politics & Election Day Tweets & 393.764 \\ \hline
Health & Medical Transcriptions & 2.348 \\ \hline
Health & Medical Speech, Transcription, and Intent & 706 \\ \hline
Job & AMAZON Job Skills & 2.505 \\ \hline
Travel & Twitter US Airline Sentiment & 14.427 \\ \hline
General & The Movies Dataset & 44.306 \\ \hline
\end{tabular}
\end{table}
Si è deciso di introdurre un topic che chiameremo \quotes{generale} questo topic ci servirà per aumentare l'eterogeneità dei dati, sono state scelte le trame dei film perchè queste sono brevi e raccontano una storia e spesso anche dei dettagli che sensibili riguardo i personaggi.

\section{Preprocessing sui raw data}
\label{sec:preprocessingraw}
I testi selezionati risultano molto eterogenei quindi prima di raggruppare tutto in un unico dataset è stata necessaria una pulizia di questi dati.\newline
Come prima cosa dai dataset scaricati sono state escluse le colonne che non erano rilevanti per la costruzione del nostro dataset ad esempio dai dataset che contenevano tweet è stata selezionata solo la colonna che contiene il testo del tweet escludendo tutte le altre colonne che contenevano altre informazioni relative al tweet quali id, autore ecc...\newline
Una volta selezionate le colonne sono stati eliminate da queste le righe che contenevano un testo di lunghezza inferiore ai 3 caratteri e che non erano in lingua inglese. La fase language detection è stata possibile grazie alla libreria Python  TextBlob\footnote{\url{https://textblob.readthedocs.io/en/dev}}.\newline
Si è notato che in dati appartenenti alla categoria lavoro risultano essere molto grandi, questo è un problema perchè potrebbe generare un numero molto alto di falsi positivi durante la fase di labeling. Per ridurre le dimensioni delle singole entry appartenti alla categoria job si è deciso di dividere in varie parti l'annuncio di lavoro, questa operazione è stata fatta utilizzando il sentence splitter\footnote{\url{https://github.com/berkmancenter/mediacloud-sentence-splitter}} \newline
Come ultima cosa dal testo contenuto in ogni riga è stata rimossa la punteggiatura, terminata questa fase i vari dataset che sono stati manipolati sono pronti per essere etichettati ed uniti.

\section{Topic classification}

\subsection{Creazione del dataset}
\label{ssec:dataset}
blablabla rimandare ai due sotto-punti.
\subsubsection{Topic Labeling}
\label{sssec:topiclabeling}
La fase di labeling è l'ultimo step prima di ottenere il dataset finale, a seconda del topic trattato nel dataset \quotes{ripulito} accanto alla colonna contenente i testi viene aggiunta una nuovo colonna esse contiene un numero che identifica il topic che viene trattato da quel testo.
\FloatBarrier
\begin{table}[h]
\centering
\begin{tabular}{|c|c|}
\hline
\textbf{Topic} & \textbf{ID} \\ \hline
Politics & 0 \\ \hline
Health & 1 \\ \hline
Job & 2 \\ \hline
Travel & 3 \\ \hline
General & 4 \\ \hline
\end{tabular}
\end{table}
Una volta completato il labeling tutti i singoli dataset vengo uniti in un unico dataset da 2 colonne(testo, topic) da più mezzo milione di righe, da queste verranno selezionati tre campioni uno da 200(\textit{ds200.csv)}, uno da 1000(\textit{ds1000.csv}) e un altro da 10.000 entry per ogni topic(\textit{ds10000.csv}).\newline
I dataset da 1000 e da 10.000 andranno in input ad un primo classificatore(il funzionamento di questo classificatore va spiegato in seguito) mentre il dataset da 200 entry per topic sarà sottoposto ad una seconda fase di labeling.

\subsubsection{Rappresentazione del testo}
\label{sssec:rappresentazione}
Per rappresentare i testi nel nostro dataset abbiamo utilizzato Universal Sentence Encoder, esso ci permette di rappresentare una frase scritta in linguaggio naturale in un vettore da 512 elementi.\newline
Abbiamo effettuato l'embed di tutti gli elementi presenti in \textit{ds1000.csv}, quindi ogni riga appartenente ad ogni topic sarà composta da un vettore da 512 elementi
\FloatBarrier
\begin{table}[h]
\centering
\begin{tabular}{|c|c|}
\hline
\textbf{Embed} & \textbf{Topic} \\ \hline
Politics{[}512{]} & 0 \\ \hline
Health{[}512{]} & 1 \\ \hline
Job{[}512{]} & 2 \\ \hline
Travel{[}512{]} & 3 \\ \hline
General{[}512{]} & 4 \\ \hline
\end{tabular}
\end{table}
Le frasi di cui è stato fatto l'embed vengono salvate in \textit{X\_embed}, mentre le label di rifiremto per ogni frase sono stata salvate i \textit{y}. Possiamo dire che \textit{X\_embed} e \textit{y} sono una nuova rappresentazione di \textit{ds1000.csv}

\subsection{Validation}
Inizialmente abbiamo diviso in due subset \textit{ds1000.csv} il primo, il \textbf{training set}, ottenuto l'80\% degli elementi scelti in maniera casuale, il secondo, il \textbf{test set} ottenuto includendo il restante 20\% degli elementi.\newline
Come detto in precedenza il dataset risulta bilanciato dato che abbiamo usato solo 1000 elementi per ogni topic, quindi per validare il modello è stata usata la 5-fold cross-validation usando il metodo \textit{GridSearchCV}.\newline
La k-fold cross-validation è una procedura di resampling utilizzata per valutare modelli di machine learning su un campione di dati limitato. La procedura ha come unico parametro \textit{k} che rappresenta il numero di quanti subset si devono creare partendo dal campione originale, nel nostro caso $ k = 5 $.
\begin{comment}
Divisione dataset 80 20
K fold cross validation 
rf si basa principalmente su numero stimatori. Abbiamo provato da m a w.

tabella di quelli provati con risultato
\end{comment}
\subsection{Testing}
Il classificatore\footnote{\url{https://github.com/CiccioTecchio/IA-Knoxly/blob/master/src/modello.py}} ha lo scopo di individuare il topic di appartenenza di una frase.\newline
Viene implementato utilizzando il metodo \textbf{Random Forest\footnote{\url{https://en.wikipedia.org/wiki/Random_forest}}}, 
esso prende in input ds1000.csv, utilizza USE per ottenere l'embed di ogni singola entry del dataset, dopodichè, la lista degli embed e la lista dei topic a cui appertiene ogni embed vengono date in input al classificatore. Esso dividerà il dataset in due parti una prima parte, l'80\%, utilizzata per l'addestramento(training set) il restante 20\% verrà utilizzato per effettuare le predizioni(test set).\newline
La tabella seguente riporta le performance ottenute da questo classificatore al termine della prima fase
\begin{table}[h]
\begin{tabular}{|l|l|c|c|c|c|c|}
\hline
\multirow{2}{*}{\textbf{Classifier}} & \multirow{2}{*}{\textbf{Metric}} & \multicolumn{5}{c|}{\textbf{Topics}} \\ \cline{3-7} 
 &  & Politics & Health & Job & Travel & General \\ \hline
\multirow{4}{*}{RF} & Accuracy & \multicolumn{5}{c|}{0.983} \\ \cline{2-7} 
 & Precision & 0.979 & 0.99 & 0.985 & 0.966 & 0.994 \\ \cline{2-7} 
 & Recall & 0.965 & 0.995 & 0.985  & 0.995 & 0.975 \\ \cline{2-7} 
 & Fscore & 0.972 & 0.992 & 0.985 & 0.980 & 0.984 \\ \hline
\end{tabular}
\caption{misure training ds1000.csv}
\end{table}
\FloatBarrier
commento delle misure.\newline
Nella seconda fase viene effettuato il \quotes{testing into the wild} dove la predizione del topic di appartenza dell'embed di una frase viene fatta su un dataset molto più grande nel nostro caso \textit{ds10000.csv}.\newline
La tabella seguente riporta le misure ottenute dalla seconda fase. 
\begin{table}[h]
\begin{tabular}{|l|l|c|c|c|c|c|}
\hline
\multirow{2}{*}{\textbf{Classifier}} & \multirow{2}{*}{\textbf{Metric}} & \multicolumn{5}{c|}{\textbf{Topics}} \\ \cline{3-7} 
 &  & Politics & Health & Job & Travel & General \\ \hline
\multirow{4}{*}{RF} & Accuracy & \multicolumn{5}{c|}{0.970} \\ \cline{2-7} 
 & Precision & 0.983 & 0.986 & 0.978 & 0.916 & 0.99 \\ \cline{2-7} 
 & Recall & 0.914 & 0.989 & 0.972 & 0.986 & 0.987 \\ \cline{2-7} 
 & Fscore & 0.947 & 0.987 & 0.975 & 0.95 & 0.988 \\ \hline
\end{tabular}
\caption{misure validation ds10.000.csv}
\end{table}
\FloatBarrier
commento delle misure.\newline

\section{Senstivity classification}

\subsection{Creazione Dataset sensitivity}

\subsubsection{Sensitive labeling}
In questa fase a ds200.csv è stata aggiunta una terza colonna denominata \quotes{sensibile}, nella quale verrà scritto \textbf{1} se la riga contiene un dato sensibile 0 altrimenti.\newline
Prima di etichettare le entry sensibili, determinare al meglio quando un dato è sensibile o meno ci siamo rifatti allo studio di Rumbald et al.\cite{dataSpectrum}

\paragraph{Tabella delle sensibilità}
In accordo allo studio fatto da Rumbal sono state identficate le seguenti regole
\FloatBarrier
\begin{table}[h]
\begin{tabular}{|l|c|}
\hline
\multicolumn{1}{|c|}{\textbf{Regole}} & \textbf{Sensibile} \\ \hline
Dati relativi ad oggetti & No \\ \hline
Dati anonimizzati relativi a persone & No \\ \hline
Dati relativi ad interazioni uomo-macchina & No \\ \hline
Dati relativi a posizione di uomini & \textbf{Sì} \\ \hline
Dati relativi ad abitudini di acquisto & No \\ \hline
Dati relativi allo stipendio & \textbf{Sì} \\ \hline
Dati relativi al lavoro svolto & \textbf{Sì} \\ \hline
Dati relativi alla propria classe sociale & \textbf{Sì} \\ \hline
Indirizzo o luogo & \textbf{Sì} \\ \hline
Chiara opinione religiosa o politica & \textbf{Sì} \\ \hline
Altri tipi di opinioni & No \\ \hline
Dati sul lifestyle & \textbf{Sì} \\ \hline
Orientamento sessuale & \textbf{Sì} \\ \hline
Sesso in generale & No \\ \hline
Dati relativi alla gravidanza & \textbf{Sì} \\ \hline
Dati relativi al gruppo etnico & \textbf{Sì} \\ \hline
Dati medici o stato di salute & \textbf{Sì} \\ \hline
\end{tabular}
\end{table}
\FloatBarrier
descrizione dettagliata delle regole?\newline
\subsection{Fase di labeling}
Una volta dettate le regole per il labeling si è proceduto ad etichettare manualmente ogni singola entry come sensibile(1) o non sensibile(0).\newline
%Dopo una prima etichettatura abbiamo ottenuto il seguente numero di topic sensibili per categoria\newline
\begin{table}[t]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Topic} & \textbf{\# entry} & \textbf{\# entry sensibili} \\ \hline
Politics & 200 & 40 \\ \hline
Health & 200 & 100 \\ \hline
Job & 200 & 21 \\ \hline
Travel & 200 & 28 \\ \hline
General & 200 & 71 \\ \hline
Totale & 1000 & 260 \\ \hline
\end{tabular}
\caption{numero entry sensibili per categoria}
\end{table}
\FloatBarrier
Si è osservato che il dataset risulta molto sbilanciato, in particolare nel topic health i tipi di interventi che ricorrono spesso sono quelli alla prostata e all'ernia, mentre nel topic job si fa riferimento a figure lavorative solo nel campo IT. Il topic più sorprendente è stato il topic General dato che i dati sensibili appartenenti ad esso fanno parte delle categorie più disparate.\newline
Per bilanciare il dataset sono state rimosse entry sensibili dai topic che ne avevano in abbondanza ed aggiungete nuove entry sensibili nei topic dove ne erano presenti di meno. Le nuove entry da aggiungere sono state selezionate manualmente da ds1000.csv, mentre le entry da rimuovere sono state quelle che trattavano argomenti ripetuti molte volte all'interno del topic.\newline
\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Topic} & \textbf{\# entry} & \textbf{\# entry sensibili} \\ \hline
Politics & 200 & 40 \\ \hline
Health & 200 & 102 \\ \hline
Job & 200 & 21 \\ \hline
Travel & 200 & 28 \\ \hline
General & 200 & 71 \\ \hline
Totale & 1000 & 262 \\ \hline
\end{tabular}
\caption{numero entry sensibili dopo il bilanciamento}
\end{table}